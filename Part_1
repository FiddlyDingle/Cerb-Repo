{
  "model": {
    "default_path": "models/",
    "context_window": 4096,
    "max_tokens": 4096,
    "temperature": 0.8,
    "gpu_layers": "auto",
    "response_format": "natural",
    "timeout_seconds": 90
  },
  "memory": {
    "max_conversations": 25,
    "embedding_model": "all-MiniLM-L6-v2",
    "similarity_threshold": 0.3,
    "auto_save": true,
    "search_result_count": 2,
    "auto_cleanup_days": 30
  },
  "ui": {
    "theme": "dark",
    "font_size": 17,
    "window_width": 1200,
    "window_height": 800,
    "auto_scroll": true,
    "font_family": "Segoe UI",
    "auto_scroll_speed": 1.0,
    "timestamp_format": "HH:MM",
    "input_height": 60,
    "chat_style": "linear",
    "split_ratio": 0.67
  },
  "performance": {
    "async_processing": true,
    "cache_embeddings": true,
    "preload_model": true,
    "max_memory_mb": 8132,
    "thread_count": 4,
    "cache_size_mb": 128
  },

  "shortcuts": {
    "send_message": "Ctrl+Enter",
    "clear_input": "Ctrl+L",
    "new_session": "Ctrl+N",
    "export_chat": "Ctrl+E"
  }
}
"""
AI Runner Pro - Core Application
Clean, optimized AI chat with persistent memory
"""

import asyncio
import json
import logging
import os
import sys
from pathlib import Path
from typing import Dict, Any, Optional

import dearpygui.dearpygui as dpg

from src.config_manager import ConfigManager
from src.model_manager import ModelManager
from src.memory_manager import MemoryManager
from src.chat_engine import ChatEngine
from src.plugin_manager import PluginManager
from src.ui_manager import UIManager

# Configure logging
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - [%(filename)s:%(lineno)d] - %(message)s',
    handlers=[
        logging.FileHandler('data/app.log', mode='a', encoding='utf-8'),
        logging.StreamHandler(sys.stderr)
    ]
)
logger = logging.getLogger(__name__)

class AIRunnerPro:
    """Main application class"""
    
    def __init__(self):
        self.config = ConfigManager("config.json")
        self.model_manager = None
        self.memory_manager = None
        self.chat_engine = None
        self.plugin_manager = None
        self.ui_manager = None
        self.running = False
        
    async def initialize(self) -> bool:
        """Initialize all components with detailed error reporting"""
        try:
            logger.info("Initializing AI Runner Pro...")
            
            # Validate configuration first
            if not self.config.is_valid():
                logger.error("Configuration validation failed:")
                logger.error(self.config.get_validation_summary())
                print("\n" + "="*60)
                print("CONFIGURATION ERROR")
                print("="*60)
                print(self.config.get_validation_summary())
                print("="*60)
                return False
            
            # Create data directory
            os.makedirs("data", exist_ok=True)
            
            # Initialize components
            logger.info("Initializing memory manager...")
            self.memory_manager = MemoryManager(self.config)
            await self.memory_manager.initialize()
            
            logger.info("Initializing model manager...")
            self.model_manager = ModelManager(self.config)
            await self.model_manager.initialize()
            
            logger.info("Initializing plugin manager...")
            self.plugin_manager = PluginManager(self.config)
            await self.plugin_manager.initialize()
            
            logger.info("Initializing chat engine...")
            self.chat_engine = ChatEngine(
                self.config, 
                self.model_manager, 
                self.memory_manager,
                self.plugin_manager,
            )
            
            logger.info("Initializing UI manager...")
            self.ui_manager = UIManager(
                self.config,
                self.chat_engine,
                self.plugin_manager,
                self.model_manager,
                self.memory_manager,
            )
            
            logger.info("AI Runner Pro initialized successfully")
            return True
            
        except Exception as e:
            logger.error(f"Initialization failed: {e}")
            logger.error("Detailed error information:", exc_info=True)
            
            # Provide user-friendly error messages
            error_msg = str(e)
            if "config" in error_msg.lower():
                print(f"\nConfiguration Error: {error_msg}")
                print("Please check your config.json file.")
            elif "model" in error_msg.lower():
                print(f"\nModel Error: {error_msg}")
                print("Please ensure model files are in the models/ directory.")
            elif "memory" in error_msg.lower():
                print(f"\nMemory Error: {error_msg}")
                print("Please ensure data/ directory is writable.")
            else:
                print(f"\nUnexpected Error: {error_msg}")
                print("Please check the logs for more details.")
            
            import traceback
            traceback.print_exc()
            return False
    
    def run(self):
        """Run the application"""
        # Initialize synchronously in main thread
        if not asyncio.run(self.initialize()):
            return
        
        self.running = True
        
        # Setup UI
        self.ui_manager.setup_ui()
        
        # Start event loop
        dpg.start_dearpygui()
        
        # Cleanup
        asyncio.run(self.shutdown())
    
    async def shutdown(self):
        """Clean shutdown"""
        logger.info("Shutting down AI Runner Pro...")
        self.running = False
        
        if self.memory_manager:
            await self.memory_manager.shutdown()
        
        if self.model_manager:
            await self.model_manager.shutdown()
        
        # Clear GPU memory
        try:
            if self.model_manager and self.model_manager.model:
                del self.model_manager.model
                self.model_manager.model = None
        except Exception as e:
            logger.warning(f"Error clearing model: {e}")

def main():
    """Main entry point"""
    app = AIRunnerPro()
    app.run()

if __name__ == "__main__":
    main()
# AI Runner Pro - Optimized Dependencies
# Core ML and LLM
llama-cpp-python>=0.2.0
sentence-transformers>=2.2.0
numpy>=1.24.0
torch>=2.0.0

# Vector search and database
faiss-cpu>=1.7.4

# UI Framework
dearpygui>=1.10.0

# Web Research Plugin Dependencies
requests>=2.31.0
beautifulsoup4>=4.12.0

# Utilities
psutil>=5.9.0
tiktoken>=0.5.0
aiofiles>=23.0.0
@echo off
title AI Runner Pro
cd /d "%~dp0"

echo ========================================
echo        AI Runner Pro - Starting
echo ========================================

if not exist venv (
    echo ERROR: Virtual environment not found
    echo Please run setup.bat first
    pause
    exit /b 1
)

echo Activating virtual environment...
call venv\Scripts\activate

echo Testing CUDA availability...
python -c "import torch; print(f'CUDA Available: {torch.cuda.is_available()}')"

echo Starting AI Runner Pro...
echo.

python main.py

if %ERRORLEVEL% neq 0 (
    echo.
    echo Application exited with error code %ERRORLEVEL%
    echo Check the logs in data\app.log for details
    pause
)
@echo off
setlocal enabledelayedexpansion
title AI Runner Pro - Setup
cd /d "%~dp0"

echo ========================================
echo     AI Runner Pro - Initial Setup
echo ========================================

if exist venv (
    echo Virtual environment already exists. Skipping creation...
) else (
    echo Creating virtual environment...
    python -m venv venv
)

echo Activating virtual environment...
call venv\Scripts\activate

echo Installing requirements...
for /L %%i in (1,1,3) do (
    pip install -r requirements.txt
    if !ERRORLEVEL! equ 0 goto :requirements_success
    echo Retry %%i failed, trying again...
    timeout /t 2 >nul
)
echo ERROR: Requirements installation failed after 3 attempts
pause
exit /b 1
:requirements_success

echo Installing CUDA PyTorch (CUDA 12.1 for RTX 3060 Ti)...
pip install torch --index-url https://download.pytorch.org/whl/cu121 --force-reinstall
if !ERRORLEVEL! neq 0 (
    echo CUDA PyTorch failed, trying CPU fallback...
    pip install torch --force-reinstall
    if !ERRORLEVEL! neq 0 (
        echo ERROR: PyTorch installation failed completely
        pause
        exit /b 1
    )
    echo WARNING: Installed CPU-only PyTorch (no GPU acceleration)
)

echo Testing CUDA availability...
python -c "import torch; print(f'CUDA Available: {torch.cuda.is_available()}')"

echo.
echo Verifying installation...
python -c "import llama_cpp, sentence_transformers, dearpygui, requests; print('‚úì All core dependencies verified')"
if !ERRORLEVEL! neq 0 (
    echo ERROR: Installation verification failed
    pause
    exit /b 1
)
echo.
echo Setup complete! Run run.bat to start the application.
pause
import os
import math

# -----------------------------
# Setup
# -----------------------------
root_dir = os.getcwd()  # Current folder where the script is located
output_dir = os.path.join(root_dir, "summaries")
os.makedirs(output_dir, exist_ok=True)

print(f"Scanning folder: {root_dir}")
print(f"Summary files will be saved in: {output_dir}")

# -----------------------------
# Function to check if file is text
# -----------------------------
def is_text_file(file_path):
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            f.read(1024)  # Try reading first 1KB
        return True
    except:
        return False

# -----------------------------
# Function to split content into 5 parts
# -----------------------------
def split_into_parts(lines, parts=6):
    n = len(lines)
    if n == 0:
        return [[] for _ in range(parts)]
    chunk_size = math.ceil(n / parts)
    return [lines[i*chunk_size : (i+1)*chunk_size] for i in range(parts)]

# -----------------------------
# Gather all text content
# -----------------------------
all_lines = []

for dirpath, dirnames, filenames in os.walk(root_dir):
    # Skip the summaries folder itself
    if dirpath.startswith(output_dir):
        continue
    for filename in filenames:
        file_path = os.path.join(dirpath, filename)
        if is_text_file(file_path):
            try:
                with open(file_path, "r", encoding="utf-8") as f:
                    all_lines.extend(f.read().splitlines())
            except Exception as e:
                print(f"[Error reading file {filename}: {e}]")
        else:
            continue

# -----------------------------
# Split and save summaries
# -----------------------------
parts = split_into_parts(all_lines, 6)

for idx, part in enumerate(parts, start=1):
    summary_file_path = os.path.join(output_dir, f"summary{idx}.txt")
    with open(summary_file_path, "w", encoding="utf-8") as sf:
        sf.write("\n".join(part))

print("All summaries have been created in the 'summaries' folder.")
#!/usr/bin/env python3
"""
Configuration Validation Script
Run this to check and fix configuration issues
"""

import sys
from pathlib import Path

# Add src to path
sys.path.insert(0, str(Path(__file__).parent / "src"))

from config_manager import ConfigManager, ConfigValidationError
from error_messaging import error_helper

def main():
    """Main validation function"""
    print("üîç AI Runner Pro - Configuration Validator")
    print("=" * 50)
    
    try:
        # Load and validate configuration
        config = ConfigManager("config.json")
        
        if config.is_valid():
            print("‚úÖ Configuration is valid!")
            print(f"üìÅ Model path: {config.get('model', 'default_path')}")
            print(f"üß† Memory: {config.get('memory', 'max_conversations')} conversations")
            print(f"üñ•Ô∏è  UI: {config.get('ui', 'window_width')}x{config.get('ui', 'window_height')}")
        else:
            print("‚ùå Configuration has issues:")
            print(config.get_validation_summary())
            
            # Attempt auto-fix
            print("\nüîß Attempting to fix issues...")
            if config.validate_and_fix():
                print("‚úÖ All issues resolved!")
            else:
                print("‚ùå Some issues remain. Manual intervention required.")
                print("\nüìñ Help:")
                print(error_helper.get_configuration_help())
                
    except ConfigValidationError as e:
        print(f"‚ùå Configuration Error: {e}")
        print("\nüìñ Help:")
        print(error_helper.get_configuration_help())
        
    except Exception as e:
        print(f"‚ùå Unexpected Error: {e}")
        import traceback
        traceback.print_exc()
    
    print("\n" + "=" * 50)
    print("üí° For more help, check the documentation or logs")

if __name__ == "__main__":
    main()
@echo off
title AI Runner Pro - Web Interface
cd /d "%~dp0"

if not exist venv (
    echo ERROR: Virtual environment not found
    echo Please run setup.bat first
    pause
    exit /b 1
)

echo Activating virtual environment...
call venv\Scripts\activate

echo Starting AI Runner Pro Web Interface...
echo Access at: http://localhost:8000
echo.

python web_server.py

pause
"""
Web Interface for AI Runner Pro - Optional FastAPI server
Run this for web access to your AI system
"""

import asyncio
import json
import logging
from pathlib import Path
from typing import Dict, Any, List

from fastapi import FastAPI, HTTPException, Request
from fastapi.responses import HTMLResponse, JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import uvicorn

from src.config_manager import ConfigManager
from src.model_manager import ModelManager
from src.memory_manager import MemoryManager
from src.chat_engine import ChatEngine
from src.plugin_manager import PluginManager

# Pydantic models
class ChatRequest(BaseModel):
    message: str
    use_memory: bool = True

class ChatResponse(BaseModel):
    response: str
    timestamp: str

# Initialize FastAPI
app = FastAPI(
    title="AI Runner Pro Web",
    description="Web interface for AI Runner Pro",
    version="1.0.0"
)

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Global components
ai_components = {}

@app.on_event("startup")
async def startup_event():
    """Initialize AI components"""
    global ai_components
    
    # Initialize components
    config = ConfigManager("config.json")
    memory_manager = MemoryManager(config)
    await memory_manager.initialize()
    
    model_manager = ModelManager(config)
    await model_manager.initialize()
    
    chat_engine = ChatEngine(config, model_manager, memory_manager)
    
    plugin_manager = PluginManager(config)
    await plugin_manager.initialize()
    
    ai_components = {
        "config": config,
        "memory_manager": memory_manager,
        "model_manager": model_manager,
        "chat_engine": chat_engine,
        "plugin_manager": plugin_manager
    }
    
    logging.info("AI Runner Pro Web interface started")

@app.get("/", response_class=HTMLResponse)
async def get_web_interface():
    """Serve web interface"""
    return """
    <!DOCTYPE html>
    <html>
    <head>
        <title>AI Runner Pro Web</title>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <style>
            body { 
                font-family: 'Segoe UI', system-ui, sans-serif; 
                margin: 0; padding: 20px; 
                background: #1a1a1a; color: #ffffff;
                line-height: 1.6;
            }
            .container { 
                max-width: 800px; margin: 0 auto; 
                background: #2d2d2d; padding: 30px; 
                border-radius: 12px; box-shadow: 0 4px 20px rgba(0,0,0,0.3);
            }
            h1 { color: #00bcd4; text-align: center; margin-bottom: 30px; }
            .chat-container { 
                height: 400px; overflow-y: auto; 
                background: #1e1e1e; padding: 20px; 
                border-radius: 8px; margin-bottom: 20px;
                border: 1px solid #444;
            }
            .message { margin-bottom: 15px; padding: 10px; border-radius: 6px; }
            .user-message { 
                background: #0d47a1; margin-left: 20px; 
                border-left: 4px solid #00bcd4;
            }
            .ai-message { 
                background: #1b5e20; margin-right: 20px;
                border-left: 4px solid #4caf50;
            }
            .input-area { display: flex; gap: 10px; align-items: flex-end; }
            textarea { 
                flex: 1; padding: 12px; border: 1px solid #555; 
                border-radius: 6px; background: #3d3d3d; 
                color: #ffffff; resize: vertical; min-height: 60px;
                font-family: inherit; font-size: 14px;
            }
            button { 
                padding: 12px 24px; background: #00bcd4; 
                color: white; border: none; border-radius: 6px; 
                cursor: pointer; font-weight: bold;
                transition: background 0.2s;
            }
            button:hover { background: #0097a7; }
            button:disabled { background: #666; cursor: not-allowed; }
            .status { 
                text-align: center; margin: 15px 0; 
                padding: 8px; border-radius: 4px;
                background: #333; font-size: 14px;
            }
            .controls { 
                display: flex; gap: 10px; margin-bottom: 15px; 
                flex-wrap: wrap; align-items: center;
            }
            select { 
                padding: 8px; background: #3d3d3d; 
                color: #ffffff; border: 1px solid #555; 
                border-radius: 4px;
            }
            label { font-size: 14px; }
        </style>
    </head>
    <body>
        <div class="container">
            <h1>AI Runner Pro Web</h1>
            
            <div class="status" id="status">Ready</div>
            
            <div class="controls">
                <label><input type="checkbox" id="useMemory" checked> Use Memory</label>
                <button onclick="clearChat()">Clear Chat</button>
                <button onclick="loadModels()">Refresh Models</button>
                <select id="modelSelect">
                    <option>Loading models...</option>
                </select>
            </div>
            
            <div class="chat-container" id="chatContainer">
                <div class="message ai-message">
                    Welcome to AI Runner Pro Web! Load a model and start chatting.
                </div>
            </div>
            
            <div class="input-area">
                <textarea 
                    id="messageInput" 
                    placeholder="Type your message here..."
                    onkeydown="handleKeyDown(event)"></textarea>
                <button onclick="sendMessage()" id="sendButton">Send</button>
            </div>
        </div>

        <script>
            let isLoading = false;

            async function sendMessage() {
                const input = document.getElementById('messageInput');
                const message = input.value.trim();
                
                if (!message || isLoading) return;
                
                isLoading = true;
                document.getElementById('sendButton').disabled = true;
                document.getElementById('sendButton').textContent = 'Sending...';
                
                // Add user message
                addMessage(message, 'user');
                input.value = '';
                
                try {
                    const response = await fetch('/chat', {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify({
                            message: message,
                            use_memory: document.getElementById('useMemory').checked
                        })
                    });
                    
                    const data = await response.json();
                    
                    if (response.ok) {
                        addMessage(data.response, 'ai');
                    } else {
                        addMessage(`Error: ${data.detail}`, 'ai');
                    }
                    
                } catch (error) {
                    addMessage(`Network error: ${error.message}`, 'ai');
                }
                
                isLoading = false;
                document.getElementById('sendButton').disabled = false;
                document.getElementById('sendButton').textContent = 'Send';
            }
            
            function addMessage(text, type) {
                const container = document.getElementById('chatContainer');
                const messageDiv = document.createElement('div');
                messageDiv.className = `message ${type}-message`;
                messageDiv.textContent = text;
                container.appendChild(messageDiv);
                container.scrollTop = container.scrollHeight;
            }
            
            function handleKeyDown(event) {
                if (event.key === 'Enter' && event.ctrlKey) {
                    sendMessage();
                }
            }
            
            function clearChat() {
                const container = document.getElementById('chatContainer');
                container.innerHTML = '<div class="message ai-message">Chat cleared.</div>';
